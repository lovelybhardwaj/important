# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s4cQ5dohHwsmRM7t3H8avsc0m5oUguZL
"""

import random
import torch
from torch.utils.data import Dataset
from torch.utils.data import sampler
import torchvision.transforms as transforms
import six
import sys
from PIL import Image
import numpy as np
import os
import sys
import numpy as np
from params import *

def club_transforms(grayscale=False,convert=True):
  transform_list=[]
  if grayscale==True:
    transform_list.append(transforms.Grayscale(1))
  if convert==True:
    transform_list.append(transforms.ToTensor())
    if grayscale==True:
      transform_list.append(transforms.Normalize((0.5,),(0.5,)))
    else:
      transform_list.append(transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)))
  return transforms.Compose(transform_list)

class TextCollator():
    def __init__(self):
        self.resolution = 16

    def __call__(self, batch):

        img_path = [item['img_path'] for item in batch]
        width = [item['img'].shape[2] for item in batch]
        indexes = [item['idx'] for item in batch]
        simgs =  torch.stack([item['simg'] for item in batch], 0)
        wcls =  torch.Tensor([item['wcl'] for item in batch])
        swids =  torch.Tensor([item['swids'] for item in batch])
        imgs = torch.ones([len(batch), batch[0]['img'].shape[0], batch[0]['img'].shape[1], max(width)], dtype=torch.float32)
        for idx, item in enumerate(batch):
            try:
                imgs[idx, :, :, 0:item['img'].shape[2]] = item['img']
            except:
                print(imgs.shape)
        item = {'img': imgs, 'img_path':img_path, 'idx':indexes, 'simg': simgs, 'swids': swids, 'wcl':wcls}
        if 'label' in batch[0].keys():
            labels = [item['label'] for item in batch]
            item['label'] = labels
        if 'z' in batch[0].keys():
            z = torch.stack([item['z'] for item in batch])
            item['z'] = z
        return item

class Test():
  def __init__(self,image_dict):
    self.IMG_DATA = image_dict
    # print(self.IMG_DATA)
    self.author_id = list(self.IMG_DATA.keys())
    self.transform=club_transforms(grayscale=True)
    self.collate_fn = TextCollator()

  def __len__(self):
    return 1

  def __getitem__(self, index):

          author_id = self.author_id[index]
          author_id
          self.IMG_DATA_AUTHOR = self.IMG_DATA[author_id]
          random_idxs = np.random.choice(len(self.IMG_DATA_AUTHOR), 73, replace = True)

          rand_id_real = np.random.choice(len(self.IMG_DATA_AUTHOR))
          real_img = self.transform(self.IMG_DATA_AUTHOR[rand_id_real]['image'].convert('L'))
          real_labels = self.IMG_DATA_AUTHOR[rand_id_real]['label'].encode()


          imgs = [np.array(self.IMG_DATA_AUTHOR[idx]['image'].convert('L')) for idx in random_idxs]
          labels = [self.IMG_DATA_AUTHOR[idx]['label'].encode() for idx in random_idxs]

          max_width = 192 #[img.shape[1] for img in imgs]

          imgs_pad = []
          imgs_wids = []


          for img in imgs:

            img = 255 - img

            img_height, img_width = img.shape[0], img.shape[1]
            outImg = np.zeros(( img_height, max_width), dtype='float32')
            outImg[:, :img_width] = img[:, :max_width]

            img = 255 - outImg
            #print(img)
            imgs_pad.append((self.transform((Image.fromarray(img)))))
            #print(imgs_pad)
            imgs_wids.append(img_width)
            #print(imgs_wids)

          imgs_pad = torch.cat(imgs_pad, 0)

          item = {'simg': imgs_pad, 'swids':imgs_wids, 'img' : real_img, 'label':real_labels,'img_path':'img_path', 'idx':'indexes', 'wcl':0}
          #HERE wcl returns the index itself
          return item